---
title             : "A survey of registration practices among observational researchers using preexisting datasets"
shorttitle        : "Explore and Confirm Analysis Workflow"
author:
  - name: Robert T. Thibault
    affiliation: '1,5'
    role:
      - Conceptualization
      - Data curation
      - Formal analysis
      - Funding acquisition
      - Investigation
      - Methodology
      - Project administration
      - Resources
      - Supervision
      - Validation
      - Visualization
      - Writing - original draft
      - Writing - review & editing
    corresponding: yes
    email: robert.thibault@stanford.edu
    address: Enter postal address here
  - name: Marton Kovacs
    affiliation: '2,6'
    role:
      - Data curation
      - Formal analysis
      - Software
      - Validation
      - Visualization
      - Writing - review & editing
    email: marton.balazs.kovacs@gmail.com
  - name: Tom E. Hardwicke
    affiliation: '3'
    role:
      - Methodology
      - Writing - review & editing
  - name: Alexandra Sarafoglou
    affiliation: '4'
    role:
      - Methodology
      - Writing - review & editing
  - name: John P. A. Ioannidis
    affiliation: '4'
    role:
      - Methodology
      - Writing - review & editing
  - name: Marcus R. Munafò
    affiliation: '1,7'
    role:
      - Conceptualization
      - Methodology
      - Supervision
      - Writing - review & editing
affiliation:
  - id: '1'
    institution: Meta-Research Innovation Center at Stanford (METRICS), Stanford University.
  - id: '2'
    institution: Doctoral School of Psychology, ELTE Eotvos Lorand University, Budapest,
      Hungary
  - id: '3'
    institution: Melbourne School of Psychological Sciences, University of Melbourne.
  - id: '4'
    institution: Department of Psychology, University of Amsterdam.
  - id: '5'
    institution: School of Psychological Science, University of Bristol.
  - id: '6'
    institution: Institute of Psychology, ELTE Eotvos Lorand University, Budapest,
      Hungary
  - id: '7'
    institution: Meta-Research Innovation Center Berlin (METRIC-B), QUEST Center for
      Transforming Biomedical Research, Berlin Institute of Health, Charité – Universitätsmedizin
      Berlin.
  - id: '8'
    institution: MRC Integrative Epidemiology Unit at the University of Bristol.
  - id: '9'
    institution: Departments of Medicine, Epidemiology and Population Health, Biomedical
      Data Science, and Statistics, Stanford University.
abstract: |
  placeholder for an abstract
  
keywords          : "keywords"
wordcount         : "X"
# bibliography      : "references.bib"
floatsintext      : yes
linenumbers       : yes
draft             : no
mask              : no
figurelist        : no
tablelist         : no
footnotelist      : no
appendix: "supplementary_materials.Rmd"

classoption       : "man"
output            : papaja::apa6_pdf
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE, warning=FALSE, message=FALSE}
library("papaja")
library(tidyverse)
library(here)
library(kableExtra)
library(gt)
library(patchwork)
# The developer version is needed
library(likert)
library(knitr)
library(viridis)
# r_refs("references.bib")
```

```{r customScripts}
# Source R scripts
r_scripts <- list.files(here::here("R/"), full.names = TRUE)
purrr::walk(r_scripts, source)
```

```{r preprocessing, include=FALSE}
# loads source data, performs preprocessing, saves raw datafiles
xfun::Rscript_call(
  rmarkdown::render,
  list(
    input = here::here("preprocessing", "ecaw_source_raw_preprocessing.Rmd"),
    output_format = "html_document"
  )
)

# loads raw data, performs preprocessing, saves processed datafiles
xfun::Rscript_call(
  rmarkdown::render,
  list(
    input = here::here("preprocessing", "ecaw_raw_processed_preprocessing.Rmd"),
    output_format = "html_document"
  )
)
```

```{r loadingData}
processed <- read_csv(here::here("data/processed/ecaw_processed_data.csv"))
processed_all <- read_csv(here::here("data/processed/ecaw_processed_all_data.csv"))
```

```{r analysisPreferences}
# Seed for random number generation
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```

# Introduction

# Methods

# Results
## Participants

```{r languageDescriptives, include=FALSE}
# List of used programming languages and their counts text
language_text <- 
  processed %>%
  rename(lang = programming_language) %>%
  separate_rows(lang, sep = ",") %>%
  count(lang) %>%
  filter(!is.na(lang)) %>%
  arrange(desc(n)) %>%
  # Removing irrelevant
  filter(lang != "irrelevant") %>%
  mutate(lang_n = glue::glue("{lang} (n = {n})")) %>%
  pull(lang_n) %>%
  glue::glue_collapse(., sep = ", ", last = ", and ")
```

```{r concernedDescriptives, include=FALSE}
# Calculate concerned percentage
concerned <- support_percentage(
  processed,
  concerned,
  c(
    "very much less concerned",
    "less concerned",
    "somewhat less concerned",
    "as concerned as a typical researcher in my field",
    "somewhat more concerned",
    "more concerned",
    # This level label starts with a capital letter
    "Very much more concerned"
  ),
  exclude_missing = TRUE
)
```

We invited the ALSPAC mailing list to participate, which included 1148 email addresses. 54 emails bounced, leaving 1094 emails that went through. The survey was completed `r nrow(processed)` times and partially completed `r nrow(processed_all) - nrow(processed) ` times, leading to a response rate of `r round(nrow(processed_all) / 1094 * 100)`% for complete surveys and `r round((nrow(processed_all) - nrow(processed)) / 1094 * 100)`% for incomplete surveys.[^1] The median time taken for complete survey responses was `r round(median(processed$duration_in_mins), 1)` minutes (IQR: `r round(quantile(processed$duration_in_mins, .25, na.rm = TRUE), 1)` to `r round(quantile(processed$duration_in_mins, .75, na.rm = T), 1)`).

Respondents published a median of `r median(processed$n_studies)` (IQR `r round(quantile(processed$n_studies, .25, na.rm = TRUE), 1)` to `r round(quantile(processed$n_studies, .75, na.rm = TRUE), 1)`) studies using preexisting observational data (Figure S1). They reported using the programming languages `r language_text` (Table S1)[^2]. `r pull(filter(concerned, support == "positive"), percentage)`% (`r pull(filter(concerned, support == "positive"), n)`/`r pull(filter(concerned, support == "positive"), n_sum)`) of participants reported being more concerned with research trustworthiness, bias, rigour, and reproducibility compared to what they think of as a typical research who uses preexisting observational data (Figure C2); `r pull(filter(concerned, support == "negative"), percentage)`% (`r pull(filter(concerned, support == "negative"), n)`/`r pull(filter(concerned, support == "negative"), n_sum)`) reported being less concerned.

[^1]: The ALSPAC mailing list has been active for >30 years and may contain email addresses that are no longer monitored. For example, we received one email reply stating that the recipient hasn’t been active in research for 30 years. Excluding these email addresses would increase the response rate, but we do not know by how much.
[^2]: Participants could select multiple responses to this survey question.
[^3]: The survey defined trustworthy as: “meaning that the results and conclusions of the publications are valid, reliable, rigorous, and accurate. That they merit trust.”
[^4]: The survey defined reproducible “in the sense that other researchers re-analysing the data with the same research question would produce similar results.”

## Survey results

```{r typicallyEcawDescriptives, include=FALSE}
# Calculate typical trustworthiness and reproducibility ratings
typically_trustworthy <- support_percentage(
  processed,
  typically_trustworthy,
  c(
    "Strongly disagree",
    "Somewhat disagree",
    "Neither agree nor disagree",
    "Somewhat agree",
    "Strongly agree"
  ),
  "I don't understand the question"
)

typically_reproducible <- support_percentage(
  processed,
  typically_reproducible,
  c(
    "Strongly disagree",
    "Somewhat disagree",
    "Neither agree nor disagree",
    "Somewhat agree",
    "Strongly agree"
  ),
  "I don't understand the question"
)

# Calculate ecaw trustworthiness and reproducibility ratings
ecaw_trustworthy <- support_percentage(
  processed,
  ecaw_trustworthy,
  c(
    "Much less",
    "Somewhat less",
    "About the same",
    "Somewhat more",
    "Much more"
  ),
  "I don't understand the question"
)

ecaw_reproducible <- support_percentage(
  processed,
  ecaw_reproducible,
  c(
    "Much less",
    "Somewhat less",
    "About the same",
    "Somewhat more",
    "Much more"
  ),
  "I don't understand the question"
)
```

Most respondents agreed that studies that analyze preexisting observational datasets are trustworthy[^3] (`r pull(filter(typically_trustworthy, support == "positive"), percentage)`%; `r pull(filter(typically_trustworthy, support == "positive"), n)`/`r pull(filter(typically_trustworthy, support == "positive"), n_sum)`) and reproducible[^4] (`r pull(filter(typically_reproducible, support == "positive"), percentage)`%; `r pull(filter(typically_reproducible, support == "positive"), n)`/`r pull(filter(typically_reproducible, support == "positive"), n_sum)`) (Figure 2, top panel). At the same time, many agreed that a study using an ECAW would be _more_ trustworthy (`r pull(filter(ecaw_trustworthy, support == "positive"), percentage)`%; `r pull(filter(ecaw_trustworthy, support == "positive"), n)`/`r pull(filter(ecaw_trustworthy, support == "positive"), n_sum)`) and _more_ reproducible (`r pull(filter(ecaw_reproducible, support == "positive"), percentage)`%; `r pull(filter(ecaw_reproducible, support == "positive"), n)`/`r pull(filter(ecaw_reproducible, support == "positive"), n_sum)`) compared to a typical study using preexisting observational data (Figure 2, bottom panel).

```{r typicallyEcawPlot, warning=FALSE, fig.cap="(ref:typicallyEcawPlotCaption)", fig.align="center", out.width="100%", fig.width=12.8, fig.height=6, fig.path='figs/', dev=c('png', 'pdf')}
# Create typically trustworthy and reproducible plot
# Check if there is any missing and don't understand responses separately
# processed %>%
#   select(contains("typically_")) %>%
#   dplyr::filter(is.na(typically_reproducible) | is.na(typically_trustworthy) | typically_reproducible == "I don't understand the question" | typically_trustworthy == "I don't understand the question") %>%
#   nrow()

# Prepare plot data
typically_plot_data <-
  processed %>%
  select(contains("typically_")) %>%
  mutate(
    across(
      .fns = ~ factor(., levels = c(
        "Strongly disagree",
        "Somewhat disagree",
        "Neither agree nor disagree",
        "Somewhat agree",
        "Strongly agree"
      ))
    )
  ) %>%
  rename(
    Reproducible = typically_reproducible,
    Trustworthy = typically_trustworthy
  )

# Create likert package data not including the missing values
typically_plot_data <- likert(typically_plot_data)

# Create figure
typically_plot <-
  plot(typically_plot_data, digits = 1, ordered = FALSE, legend.position = "right", text.size = 5) +
  scale_y_continuous(labels = c("100%", "50%", "0%", "50%", "100%"), limits = c(-105, 105)) +
  labs(title = "Typically, studies that analyze preexisting observational datasets\n(such as the ALSPAC dataset) are...") +
  theme(
    title = element_text(size = 14),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 15),
    axis.title.x = element_blank(),
    legend.text = element_text(size = 13.5),
    legend.title = element_blank()
  )

# Create ecaw trustworthy and reproducible plot
# Calculate missing responses
ecaw_missing <-
  processed %>%
  select(contains("ecaw_")) %>%
  pivot_longer(
    cols = everything(),
    names_to = "item",
    values_to = "value"
  ) %>%
  dplyr::filter(is.na(value) | value == "I don't understand the question") %>%
  mutate(item = str_to_title(str_remove(item, "^[^_]*_"))) %>%
  replace_na(list(value = "Missing")) %>%
  group_by(item, value) %>%
  summarise(
    n = n()
  )

# Prepare plot data
ecaw_plot_data <-
  processed %>%
  select(contains("ecaw_")) %>%
  # Transform not wanted response values to NA
  # likert::likert drops NA values silently
  # When var transformed to factor these values would be transformed to NA
  # Automatically but I try to be explicit
  mutate(
    across(
      everything(),
      ~ case_when(
        . == "I don't understand the question" ~ NA_character_,
        TRUE ~ .
      )
    )
  ) %>%
  mutate(
    across(
      .fns = ~ factor(., levels = c(
        "Much less",
        "Somewhat less",
        "About the same",
        "Somewhat more",
        "Much more"
      ))
    )
  ) %>%
  rename(
    Reproducible = ecaw_reproducible,
    Trustworthy = ecaw_trustworthy
  )

# Create likert package data not including the missing values
ecaw_plot_data <- likert(ecaw_plot_data)

# Create figure
ecaw_plot <-
  plot(ecaw_plot_data, digits = 1, ordered = FALSE, legend.position = "right", text.size = 5) +
  scale_y_continuous(labels = c("100%", "50%", "0%", "50%", "100%"), limits = c(-105, 105)) +
  labs(title = "Compared to a typical study using preexisting observational data,\na study using an ECAW would be...") +
  theme(
    title = element_text(size = 14),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 15),
    axis.title.x = element_blank(),
    legend.text = element_text(size = 13.5),
    legend.title = element_blank(),
    legend.box.margin = margin(t = 0, r = 0, b = 0, l = -2.3, unit = "cm")
  )

# Join the two plots together to make one figure
typically_plot + ecaw_plot + plot_layout(ncol = 1, nrow = 2)
```

(ref:typicallyEcawPlotCaption) __Responses to the survey questions on trustworthiness and reproducibility of observational research with preexisting data and ECAWs.__ The survey defined trustworthy as “meaning that the results and conclusions of the publications are valid, reliable, rigorous, and accurate. That they merit trust”. The survey defined reproducible “in the sense that other researchers re-analysing the data with the same research question would produce similar results.” For each item, the number to the left of the data bar indicates the combined percentage for the responses depicted in any shade of brown/orange. The number in the center of the data bar (gray) indicates the percentage of neutral responses. The number to the right of the data bar indicates the combined percentage for the responses depicted in any shade of green. For the bottom panel we excluded the missing responses (n = `r pull(filter(ecaw_missing, item == "Trustworthy" & value == "Missing"), n)`; `r pull(filter(ecaw_missing, item == "Reproducible" & value == "Missing"), n)`) and responses of “I don't understand the question” (n = `r pull(filter(ecaw_missing, item == "Trustworthy" & value == "I don't understand the question"), n)`; `r pull(filter(ecaw_missing, item == "Reproducible" & value == "I don't understand the question"), n)`).

```{r methodDescriptives, include=FALSE}
# Define the response level order for these variables
method_levels <- c(
  "Never or almost never",
  "Sometimes",
  "About half the time",
  "Most of the time",
  "Always or almost always",
  "I don't understand the question",
  "Missing"
)

# Calculate the frequency and proportion of responses for each response level
confirmatory <- level_percentage(
  processed,
  method_confirmatory,
  method_levels,
  exclude_missing = FALSE
) %>%
  filter(method_confirmatory %in% c("Sometimes", "About half the time", "Most of the time", "Always or almost always")) %>%
  summarise(
    n = sum(n),
    # Since n_sum should be the same for the whole dataset we can use unique to return one value
    n_sum = unique(n_sum),
    percentage = sum(percentage))

exploratory <- level_percentage(
  processed,
  method_exploratory,
  method_levels,
  exclude_missing = FALSE
) %>%
  dplyr::filter(method_exploratory  %in% c("Sometimes", "About half the time", "Most of the time", "Always or almost always")) %>%
  summarise(
    n = sum(n),
    # Since n_sum should be the same for the whole dataset we can use unique to return one value
    n_sum = unique(n_sum),
    percentage = sum(percentage))

preregistered <- level_percentage(
  processed,
  method_preregistered,
  method_levels,
  exclude_missing = FALSE
)

blind <- level_percentage(
  processed,
  method_blind,
  method_levels,
  exclude_missing = FALSE
)

script <- level_percentage(
  processed,
  method_script,
  method_levels,
  exclude_missing = FALSE
)
```

Over half of respondents reported that their studies using preexisting observational data are preregistered never or almost never (`r filter(preregistered, method_preregistered == "Never or almost never") %>% pull(percentage)`%; `r filter(preregistered, method_preregistered == "Never or almost never") %>% pull(n)`/`r filter(preregistered, method_preregistered == "Never or almost never") %>% pull(n_sum)`), or sometimes (`r filter(preregistered, method_preregistered == "Sometimes") %>% pull(percentage)`%; `r filter(preregistered, method_preregistered == "Sometimes") %>% pull(n)`/`r filter(preregistered, method_preregistered == "Sometimes") %>% pull(n_sum)`) (Figure 2A). About half reported sharing their analysis scripts never or almost never (`r filter(script, method_script == "Never or almost never") %>% pull(percentage)`%; `r filter(script, method_script == "Never or almost never") %>% pull(n)`/`r filter(script, method_script == "Never or almost never") %>% pull(n_sum)`), or sometimes (`r filter(script, method_script == "Sometimes") %>% pull(percentage)`%; `r filter(script, method_script == "Sometimes") %>% pull(n)`/`r filter(script, method_script == "Sometimes") %>% pull(n_sum)`) (Figure 3). `r filter(blind, method_blind == "Never or almost never") %>% pull(percentage)`% (`r filter(blind, method_blind == "Never or almost never") %>% pull(n)`/`r filter(blind, method_blind == "Never or almost never") %>% pull(n_sum)`) reported that they never or almost never blind the data analyst (Figure 3). Almost all respondents answered that they use both exploratory (`r pull(exploratory, percentage)`%; `r pull(exploratory, n)`/`r pull(exploratory, n_sum)`) and confirmatory (`r pull(confirmatory, percentage)`%; `r pull(confirmatory, n)`/`r pull(confirmatory, n_sum)`) analyses at least sometimes (Figure 3).

```{r methodPlot, warning=FALSE, fig.cap="(ref:methodPlotCaption)", fig.align="center", out.width="100%", fig.width=11, fig.height=4.5, fig.path='figs/', dev=c('png', 'pdf')}
# Used methods figures
method_plot_data <-
  processed %>%
  select(starts_with("method_")) %>%
  pivot_longer(
    cols = everything(),
    names_to = "variable",
    values_to = "scale",
  ) %>%
  separate(variable, into = c("name_prefix", "type")) %>%
  group_by(type) %>%
  count(scale) %>%
  ungroup() %>%
  replace_na(list(scale = "Missing")) %>%
  mutate(
    scale = factor(scale, levels = c(
      "Never or almost never",
      "Sometimes",
      "About half the time",
      "Most of the time",
      "Always or almost always",
      "Missing",
      "I don't understand the question"
    )),
    type = case_when(
      type == "blind" ~ "Blind the data analyst",
      type == "confirmatory" ~ "Contain confirmatory analysis",
      type == "exploratory" ~ "Contain exploratory analysis",
      type == "preregistered" ~ "Are preregistered",
      type == "script" ~ "Share analysis scripts",
    ),
    type = factor(type, levels = c(
      "Contain exploratory analysis",
      "Contain confirmatory analysis",
      "Blind the data analyst",
      "Share analysis scripts",
      "Are preregistered"
    ))
  ) %>%
  group_by(type) %>%
  tidyr::complete(scale, fill = list(n = 0)) %>%
  mutate(
    percentage = n / sum(n)
  ) %>%
  ungroup()

# method_missing_data <-
#   method_data %>%
#   filter(scale %in% c("Missing", "I don't understand the question")) %>%
#   mutate(
#     scale = case_when(
#       scale == "I don't understand the question" ~ "Don't understand",
#       scale == "Missing" ~ "Missing"),
#     text = paste0(scale, ": ", n)
#     ) %>%
#   group_by(type) %>%
#   summarise(text = stringr::str_c(text, collapse = "\n"))

method_plot_data %>%
  # filter(scale %ni% c("Missing", "I don't understand the question")) %>%
  ggplot() +
  aes(
    x = percentage,
    y = type,
    fill = scale
  ) +
  geom_bar(position = "stack", stat = "identity") +
  scale_x_continuous(
    limits = c(0, 1),
    labels = scales::label_percent()
  ) +
  scale_fill_viridis(option = "A", discrete = TRUE) +
  scale_y_discrete(labels = function(x) str_wrap(x, width = 20)) +
  labs(
    title = "The studies using preexisting observational data that I am involved in..."
  ) +
  papaja::theme_apa() +
  theme(
    title = element_text(size = 17),
    axis.text = element_text(size = 15),
    axis.title.x = element_blank(),
    axis.title.y = element_blank(),
    legend.text = element_text(size = 14),
    legend.title = element_blank(),
    legend.box.margin = margin(t = 0, r = 0, b = 0, l = -0.5, unit = "cm")
  )
```

(ref:methodPlotCaption) __Responses to survey questions about the research practices of participants.__

```{r aslpacDescriptives, include=FALSE, warning=FALSE, message=FALSE}
willing <- support_percentage(
  processed,
  alspac_less_willing,
  c(
    "Strongly disagree",
    "Somewhat disagree",
    "Neither agree nor disagree",
    "Somewhat agree",
    "Strongly agree"
  ),
  c(
    "I don't understand the question",
    "Unsure"
  )
)

opt <- support_percentage(
  processed,
  alspac_opt_in,
  c(
    "Strongly disagree",
    "Somewhat disagree",
    "Neither agree nor disagree",
    "Somewhat agree",
    "Strongly agree"
  ),
  c(
    "I don't understand the question",
    "Unsure"
  )
)

study <- support_percentage(
  processed,
  alspac_study,
  c(
    "Strongly disagree",
    "Somewhat disagree",
    "Neither agree nor disagree",
    "Somewhat agree",
    "Strongly agree"
  ),
  c(
    "I don't understand the question",
    "Unsure"
  )
)

prefer <- support_percentage(
  processed,
  alspac_prefer_ecaw,
  c(
    "Strongly disagree",
    "Somewhat disagree",
    "Neither agree nor disagree",
    "Somewhat agree",
    "Strongly agree"
  ),
  c(
    "I don't understand the question",
    "Unsure"
  )
)
```

`r pull(filter(willing, support == "positive"), percentage)`% (`r pull(filter(willing, support == "positive"), n)`/`r pull(filter(willing, support == "positive"), n_sum)`) of respondents agreed (versus `r pull(filter(willing, support == "negative"), percentage)`%; `r pull(filter(willing, support == "negative"), n)`/`r pull(filter(willing, support == "negative"), n_sum)` who disagreed) that they would be less willing to use ALSPAC data if they were required to use an ECAW (Figure 3). `r pull(filter(opt, support == "positive"), percentage)`% (`r pull(filter(opt, support == "positive"), n)`/`r pull(filter(opt, support == "positive"), n_sum)`) agreed (`r pull(filter(opt, support == "negative"), percentage)`%; `r pull(filter(opt, support == "negative"), n)`/`r pull(filter(opt, support == "negative"), n_sum)` disagreed) that they would opt-in if ALSPAC ran a study on ECAWs. `r pull(filter(study, support == "positive"), percentage)`% (`r pull(filter(study, support == "positive"), n)`/`r pull(filter(study, support == "positive"), n_sum)`) agreed (`r pull(filter(study, support == "negative"), percentage)`%; `r pull(filter(study, support == "negative"), n)`/`r pull(filter(study, support == "negative"), n_sum)` disagreed) that ALSPAC should run a study on ECAWs. `r pull(filter(prefer, support == "positive"), percentage)`% (`r pull(filter(prefer, support == "positive"), n)`/`r pull(filter(prefer, support == "positive"), n_sum)`) agreed (`r pull(filter(prefer, support == "negative"), percentage)`%; `r pull(filter(prefer, support == "negative"), n)`/`r pull(filter(prefer, support == "negative"), n_sum)` disagreed) that they would prefer using an ECAW than using typical preregistration.

```{r alspacPlot, warning=FALSE, message=FALSE, fig.cap="(ref:alspacPlotCaption)", fig.align="center", out.width="100%", fig.width=14, fig.height=5, fig.path='figs/', dev=c('png', 'pdf')}
# Check if there is any missing and don't understand responses separately
alspac_missing <-
  processed %>%
  select(contains("alspac_")) %>%
  pivot_longer(
    cols = everything(),
    names_to = "item",
    values_to = "value"
  ) %>%
  dplyr::filter(is.na(value) | value == "I don't understand the question" | value == "Unsure") %>%
  mutate(
    item = str_to_title(str_remove(item, "^[^_]*_")),
    # We reorder it by making it a factor
    item = factor(item, levels = c(
      "Less_willing",
      "Opt_in",
      "Study",
      "Prefer_ecaw"
    )),
    # By making it a factor we can complete missing levels in the data later
    value = factor(value, levels = c(
      "Missing",
      "I don't understand the question",
      "Unsure"
    ))
  ) %>%
  replace_na(list(value = "Missing")) %>%
  group_by(item, value) %>%
  summarise(
    n = n()
  ) %>% 
  # Add n = 0 if no one choose a specific factor level
  tidyr::complete(value, fill = list(n = 0)) 

# Prepare plot data
alspac_plot_data <-
  processed %>%
  select(contains("alspac_")) %>%
  # Transform not wanted response values to NA
  # likert::likert drops NA values silently
  # When var transformed to factor these values would be transformed to NA
  # Automatically but I try to be explicit
  mutate(
    across(
      everything(),
      ~ case_when(
        . %in% c("I don't understand the question", "Unsure") ~ NA_character_,
        TRUE ~ .
      )
    )
  ) %>%
  mutate(
    across(
      .fns = ~ factor(., levels = c(
        "Strongly disagree",
        "Somewhat disagree",
        "Neither agree nor disagree",
        "Somewhat agree",
        "Strongly agree"
      ))
    )
  ) %>%
  rename(
    `If ALSPAC required that I use an ECAW, I would be less willing to use their data in my research` = alspac_less_willing,
    `If ALSPAC ran a study on ECAWs, I would opt-in.` = alspac_opt_in,
    `ALSPAC should run a study on ECAWs.` = alspac_study,
    `I would prefer using an ECAW than using typical preregistration` = alspac_prefer_ecaw
  )

# Create likert package data not including the missing values
alspac_plot_likert_data <- likert(alspac_plot_data)

# Create figure
plot(alspac_plot_likert_data, digits = 1, text.size = 6) +
  # TODO: have to check if this is not messing with the results
  scale_x_discrete(labels = function(x) str_wrap(x, width = 30), limits = rev(names(alspac_plot_data))) +
  scale_y_continuous(labels = c("100%", "50%", "0%", "50%", "100%"), limits = c(-105, 105)) +
  labs(title = "Thinking about a study you may run with ALSPAC data (or one that you have recently run)...") +
  theme(
    axis.title.x = element_blank(),
    title = element_text(size = 15.5),
    axis.text.y = element_text(size = 14),
    axis.text.x = element_text(size = 16),
    legend.text = element_text(size = 15),
    legend.title = element_blank()
  )
```

(ref:alspacPlotCaption) __Responses to survey questions about using ECAWs.__ For the 4 questions we excluded missing values (_n_ = `r pull(filter(alspac_missing, item == "Less_willing" & value == "Missing"), n)`; `r pull(filter(alspac_missing, item == "Opt_in" & value == "Missing"), n)`; `r pull(filter(alspac_missing, item == "Study" & value == "Missing"), n)`; `r pull(filter(alspac_missing, item == "Prefer_ecaw" & value == "Missing"), n)`), responses of "I don't understand the question" (_n_ = `r pull(filter(alspac_missing, item == "Less_willing" & value == "I don't understand the question"), n)`; `r pull(filter(alspac_missing, item == "Opt_in" & value == "I don't understand the question"), n)`; `r pull(filter(alspac_missing, item == "Study" & value == "I don't understand the question"), n)`; `r pull(filter(alspac_missing, item == "Prefer_ecaw" & value == "I don't understand the question"), n)`), and responses of "Unsure" (_n_ = `r pull(filter(alspac_missing, item == "Less_willing" & value == "Unsure"), n)`; `r pull(filter(alspac_missing, item == "Opt_in" & value == "Unsure"), n)`; `r pull(filter(alspac_missing, item == "Study" & value == "Unsure"), n)`; `r pull(filter(alspac_missing, item == "Prefer_ecaw" & value == "Unsure"), n)`).

```{r include=FALSE}
# Open ended questions
open_ended <-
  processed %>%
  select(response_id, unsure_explain, drawback_ecaw, suggestions, comments) %>%
  pivot_longer(cols = c(unsure_explain, drawback_ecaw, suggestions, comments), names_to = "variable", values_to = "value") %>%
  filter(!is.na(value))
```

Table 1. Recurring topics in responses to the open-ended survey questions. The survey included 4 open-ended questions with broad prompts regarding running a study on ECAWs, benefits and drawbacks of ECAWs, related research practices, and general comments. These questions received a total of (`r nrow(open_ended)`) responses from (`r nrow(distinct(open_ended, response_id))`) unique respondents. A complete list of responses are viewable in the open data [LINK]. We synthesized the response to open-ended questions into the 9 topics on the left side of this table. We divide these into three sections: (i) concerns about the acceptability of ECAWs, (ii) concerns that ECAWs will not have their intended impact, and (iii) alternative interventions that may achieve similar goals as typical preregistration and ECAWs. On the right side of the table, we provide a reflection on each topic. 

## Exploratory analyses

# Discussion

# Acknowledgements


\newpage

# References

::: {#refs custom-style="Bibliography"}
:::


\newpage

# (APPENDIX) Appendix {-}

```{r child = "supplementary_materials.Rmd"}
```
